{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploy Red Bull Receipt OCR API (Colab)\n",
        "\n",
        "‚ö†Ô∏è IMPORTANT: Set Runtime to GPU (T4, L4, or A100).\\n\\n",
        "This notebook creates a FastAPI server (with optional public URL via ngrok) for scanning receipts using your fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# ===========================\n",
        "# STEP 1: Install Dependencies\n",
        "# ===========================\n",
        "print(\"=\"*60)\n",
        "print(\"üì¶ INSTALLING DEPENDENCIES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!pip install -q transformers torch torchvision pillow\n",
        "!pip install -q fastapi uvicorn pyngrok python-multipart\n",
        "!pip install -q timm einops\n",
        "\n",
        "print(\"‚úì Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# STEP 2: Mount Drive and Load Model\n",
        "# ===========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ü§ñ LOADING MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Scan Bill/trained_model\"\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"‚ùå Model not found at: {MODEL_PATH}\")\n",
        "    print(\"\\nPlease check your model location or update MODEL_PATH\")\n",
        "    raise FileNotFoundError(\"Model not found\")\n",
        "\n",
        "print(f\"Loading model from: {MODEL_PATH}\")\n",
        "\n",
        "# Load model\n",
        "model = AutoModel.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True,\n",
        "    device_map='auto'\n",
        ").eval()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL_PATH, \n",
        "    trust_remote_code=True, \n",
        "    use_fast=False\n",
        ")\n",
        "\n",
        "print(\"‚úì Model loaded successfully\")\n",
        "print(f\"  Device: {next(model.parameters()).device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"  Memory: CUDA not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# STEP 3: Image Processing Functions\n",
        "# ===========================\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def build_transform(input_size):\n",
        "    transform = T.Compose([\n",
        "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
        "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "    ])\n",
        "    return transform\n",
        "\n",
        "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
        "    best_ratio_diff = float('inf')\n",
        "    best_ratio = (1, 1)\n",
        "    area = width * height\n",
        "    for ratio in target_ratios:\n",
        "        target_aspect_ratio = ratio[0] / ratio[1]\n",
        "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
        "        if ratio_diff < best_ratio_diff:\n",
        "            best_ratio_diff = ratio_diff\n",
        "            best_ratio = ratio\n",
        "        elif ratio_diff == best_ratio_diff:\n",
        "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
        "                best_ratio = ratio\n",
        "    return best_ratio\n",
        "\n",
        "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
        "    orig_width, orig_height = image.size\n",
        "    aspect_ratio = orig_width / orig_height\n",
        "\n",
        "    target_ratios = set(\n",
        "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) \n",
        "        for j in range(1, n + 1) if i * j <= max_num and i * j >= min_num)\n",
        "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
        "\n",
        "    target_aspect_ratio = find_closest_aspect_ratio(\n",
        "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
        "\n",
        "    target_width = int(image_size * target_aspect_ratio[0])\n",
        "    target_height = int(image_size * target_aspect_ratio[1])\n",
        "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
        "\n",
        "    resized_img = image.resize((target_width, target_height))\n",
        "    processed_images = []\n",
        "    \n",
        "    for i in range(blocks):\n",
        "        box = (\n",
        "            (i % (target_width // image_size)) * image_size,\n",
        "            (i // (target_width // image_size)) * image_size,\n",
        "            ((i % (target_width // image_size)) + 1) * image_size,\n",
        "            ((i // (target_width // image_size)) + 1) * image_size\n",
        "        )\n",
        "        split_img = resized_img.crop(box)\n",
        "        processed_images.append(split_img)\n",
        "    \n",
        "    if use_thumbnail and len(processed_images) != 1:\n",
        "        thumbnail_img = image.resize((image_size, image_size))\n",
        "        processed_images.append(thumbnail_img)\n",
        "    \n",
        "    return processed_images\n",
        "\n",
        "def load_image(image, input_size=448, max_num=12):\n",
        "    \"\"\"Process PIL Image for model inference\"\"\"\n",
        "    if isinstance(image, str):\n",
        "        image = Image.open(image).convert('RGB')\n",
        "    \n",
        "    transform = build_transform(input_size=input_size)\n",
        "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
        "    pixel_values = [transform(img) for img in images]\n",
        "    pixel_values = torch.stack(pixel_values)\n",
        "    return pixel_values\n",
        "\n",
        "def extract_receipt_info(image):\n",
        "    \"\"\"Extract receipt information from image\"\"\"\n",
        "    try:\n",
        "        # Process image\n",
        "        pixel_values = load_image(image, max_num=12).to(torch.bfloat16)\n",
        "        if torch.cuda.is_available():\n",
        "            pixel_values = pixel_values.cuda()\n",
        "        \n",
        "        # Generate response\n",
        "        question = \"<image>\\nTr√≠ch xu·∫•t th√¥ng tin h√≥a ƒë∆°n trong ·∫£nh d∆∞·ªõi d·∫°ng JSON.\"\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            response = model.chat(\n",
        "                tokenizer, \n",
        "                pixel_values, \n",
        "                question, \n",
        "                generation_config=dict(\n",
        "                    max_new_tokens=1024, \n",
        "                    do_sample=False,\n",
        "                    num_beams=3,\n",
        "                    repetition_penalty=2.0\n",
        "                )\n",
        "            )\n",
        "        \n",
        "        # Try to parse as JSON\n",
        "        try:\n",
        "            # Clean response if it has markdown code blocks\n",
        "            if isinstance(response, str) and response.startswith('```'):\n",
        "                response = response.split('```')[1]\n",
        "                if response.startswith('json'):\n",
        "                    response = response[4:]\n",
        "            \n",
        "            result = json.loads(response) if isinstance(response, str) else response\n",
        "            return {\"success\": True, \"data\": result, \"raw_response\": response}\n",
        "        except json.JSONDecodeError:\n",
        "            # Return raw response if not valid JSON\n",
        "            return {\"success\": True, \"data\": None, \"raw_response\": response}\n",
        "            \n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "print(\"\\n‚úì Image processing functions ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# STEP 4: Create FastAPI Server\n",
        "# ===========================\n",
        "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
        "from fastapi.responses import JSONResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import io\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"Red Bull Receipt OCR API\",\n",
        "    description=\"Extract receipt information from images using fine-tuned Vintern model\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "# Enable CORS for all origins\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    \"\"\"API root endpoint\"\"\"\n",
        "    return {\n",
        "        \"message\": \"Red Bull Receipt OCR API\",\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"endpoints\": {\n",
        "            \"POST /scan\": \"Upload image to extract receipt information\",\n",
        "            \"POST /scan_base64\": \"Send base64 encoded image\",\n",
        "            \"GET /health\": \"Check API health status\"\n",
        "        },\n",
        "        \"model\": \"Vintern-1B-v3_5 (Fine-tuned on Red Bull receipts)\"\n",
        "    }\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"model_loaded\": model is not None,\n",
        "        \"gpu_available\": torch.cuda.is_available(),\n",
        "        \"gpu_memory_used_gb\": (torch.cuda.memory_allocated() / 1024**3) if torch.cuda.is_available() else 0\n",
        "    }\n",
        "\n",
        "@app.post(\"/scan\")\n",
        "async def scan_receipt(file: UploadFile = File(...)):\n",
        "    \"\"\"\n",
        "    Scan receipt image and extract information\n",
        "    \n",
        "    Args:\n",
        "        file: Image file (jpg, png, jpeg, bmp)\n",
        "    \n",
        "    Returns:\n",
        "        JSON with extracted receipt information\n",
        "    \"\"\"\n",
        "    # Validate file type\n",
        "    if not file.content_type.startswith('image/'):\n",
        "        raise HTTPException(status_code=400, detail=\"File must be an image\")\n",
        "    \n",
        "    try:\n",
        "        # Read image\n",
        "        contents = await file.read()\n",
        "        image = Image.open(io.BytesIO(contents))\n",
        "        \n",
        "        # Extract information\n",
        "        result = extract_receipt_info(image)\n",
        "        \n",
        "        if result[\"success\"]:\n",
        "            return JSONResponse(content={\n",
        "                \"success\": True,\n",
        "                \"filename\": file.filename,\n",
        "                \"extracted_data\": result.get(\"data\"),\n",
        "                \"raw_response\": result.get(\"raw_response\")\n",
        "            })\n",
        "        else:\n",
        "            raise HTTPException(status_code=500, detail=result[\"error\"])\n",
        "            \n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing image: {str(e)}\")\n",
        "\n",
        "@app.post(\"/scan_base64\")\n",
        "async def scan_receipt_base64(data: dict):\n",
        "    \"\"\"\n",
        "    Scan receipt from base64 encoded image\n",
        "    \n",
        "    Args:\n",
        "        data: {\"image\": \"base64_encoded_string\"}\n",
        "    \n",
        "    Returns:\n",
        "        JSON with extracted receipt information\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import base64\n",
        "        \n",
        "        if \"image\" not in data:\n",
        "            raise HTTPException(status_code=400, detail=\"Missing 'image' field in request body\")\n",
        "        \n",
        "        # Decode base64\n",
        "        image_data = base64.b64decode(data[\"image\"])\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "        \n",
        "        # Extract information\n",
        "        result = extract_receipt_info(image)\n",
        "        \n",
        "        if result[\"success\"]:\n",
        "            return JSONResponse(content={\n",
        "                \"success\": True,\n",
        "                \"extracted_data\": result.get(\"data\"),\n",
        "                \"raw_response\": result.get(\"raw_response\")\n",
        "            })\n",
        "        else:\n",
        "            raise HTTPException(status_code=500, detail=result[\"error\"])\n",
        "            \n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing image: {str(e)}\")\n",
        "\n",
        "print(\"\\n‚úì FastAPI server created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# STEP 5: Setup ngrok for Public URL\n",
        "# ===========================\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üåê SETTING UP PUBLIC URL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get ngrok auth token\n",
        "print(\"\\nüìù To get a public URL, you need an ngrok auth token:\")\n",
        "print(\"   1. Go to: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "print(\"   2. Sign up (free)\")\n",
        "print(\"   3. Copy your authtoken\")\n",
        "print()\n",
        "\n",
        "ngrok_token = getpass.getpass(\"Enter your ngrok authtoken (or press Enter to skip): \")\n",
        "\n",
        "if ngrok_token:\n",
        "    conf.get_default().auth_token = ngrok_token\n",
        "    print(\"‚úì ngrok token configured\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Running without ngrok - only local access available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# STEP 6: Start Server\n",
        "# ===========================\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from threading import Thread\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ STARTING API SERVER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Start ngrok tunnel if token provided\n",
        "public_url = None\n",
        "if ngrok_token:\n",
        "    try:\n",
        "        # Kill existing tunnels\n",
        "        ngrok.kill()\n",
        "        \n",
        "        # Create new tunnel\n",
        "        public_url = ngrok.connect(8000)\n",
        "        print(f\"\\n‚úÖ PUBLIC URL: {public_url}\")\n",
        "        print(f\"   Share this URL with anyone to access your API!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not create ngrok tunnel: {e}\")\n",
        "        print(\"   Server will run locally only\")\n",
        "\n",
        "print(f\"\\nüìç Local URL: http://localhost:8000\")\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"API ENDPOINTS:\")\n",
        "print(\"=\"*60)\n",
        "if public_url:\n",
        "    print(f\"POST {public_url}/scan - Upload image file\")\n",
        "    print(f\"POST {public_url}/scan_base64 - Send base64 image\")\n",
        "    print(f\"GET  {public_url}/health - Health check\")\n",
        "    print(f\"GET  {public_url}/docs - Interactive API documentation\")\n",
        "else:\n",
        "    print(\"POST http://localhost:8000/scan - Upload image file\")\n",
        "    print(\"POST http://localhost:8000/scan_base64 - Send base64 image\")\n",
        "    print(\"GET  http://localhost:8000/health - Health check\")\n",
        "    print(\"GET  http://localhost:8000/docs - Interactive API documentation\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìñ USAGE EXAMPLES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n1Ô∏è‚É£ Using cURL:\")\n",
        "if public_url:\n",
        "    print(f'''\ncurl -X POST \"{public_url}/scan\" \\n  -F \"file=@receipt.jpg\"\n''')\n",
        "else:\n",
        "    print('''\ncurl -X POST \"http://localhost:8000/scan\" \\\n  -F \"file=@receipt.jpg\"\n''')\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£ Using Python:\")\n",
        "print(f'''\nimport requests\n\nurl = \"{public_url or 'http://localhost:8000'}/scan\"\nfiles = {{'file': open('receipt.jpg', 'rb')}}\nresponse = requests.post(url, files=files)\nprint(response.json())\n''')\n",
        "\n",
        "print(\"\\n3Ô∏è‚É£ Using JavaScript:\")\n",
        "print(f'''\nconst formData = new FormData();\nformData.append('file', fileInput.files[0]);\n\nfetch('{public_url or 'http://localhost:8000'}/scan', {{\n  method: 'POST',\n  body: formData\n}})\n.then(response => response.json())\n.then(data => console.log(data));\n''')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚ö° SERVER RUNNING - Press Stop/Interrupt to stop\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Start server (blocking)\n",
        "config = uvicorn.Config(\n",
        "    app=app,\n",
        "    host=\"0.0.0.0\",\n",
        "    port=8000,\n",
        "    log_level=\"info\"\n",
        ")\n",
        "server = uvicorn.Server(config)\n",
        "server.run()\n",
        "\n",
        "# ===========================\n",
        "# NOTE: Server runs until interrupted\n",
        "# ===========================\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

